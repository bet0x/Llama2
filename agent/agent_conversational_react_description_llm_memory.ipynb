{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "Using Conversational React Agent to interact with our llm tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from togetherllm import TogetherLLM\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import Tool, AgentExecutor, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains import LLMMathChain\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain import PromptTemplate, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = TogetherLLM(\n",
    "    model= \"togethercomputer/llama-2-7b-chat\",\n",
    "    temperature=0,\n",
    "    max_tokens=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"instruction\"],\n",
    "    template=\"{instruction}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "# Read Excel file\n",
      "df = pd.read_excel('file.xlsx')\n",
      "\n",
      "# Convert to CSV\n",
      "df.to_csv('output.csv', index=False)\n",
      "\n",
      "# Write the CSV file\n",
      "with open('output.csv', 'w', newline='') as csvfile:\n",
      "    writer = csv.writer(csvfile)\n",
      "    writer.writerow(['Name', 'Age', 'Gender'])\n",
      "    for row in df:\n",
      "        writer.writerow(row)\n",
      "\n",
      "This code reads an Excel file using pandas and converts it to a CSV file. The `to_csv()` method is used to write the data to a CSV file. The `index=False` parameter is used to exclude the sheet index from the CSV file. The `with open()` statement is used to open the CSV file in write mode and create a csv writer object. The `writerow()` method is used to write each row of the data to the CSV file.\n",
      "\n",
      "You can also use the `to_csv()` method with the `index=False` parameter to write the data to a CSV file without the sheet index.\n",
      "```\n",
      "df.to_csv('output.csv', index=False)\n",
      "```\n",
      "You can also use the `to_csv()` method with the `orient='index'` parameter to write the data to a CSV file with the sheet index included.\n",
      "```\n",
      "df.to_csv('output.csv', orient='index')\n",
      "```\n",
      "You can also use the `to_csv()` method with the `mode='w'` parameter to write the data to a CSV file overwriting any existing file.\n",
      "```\n",
      "df.to_csv('output.csv', mode='w')\n",
      "```\n",
      "You can also use the `to_csv()` method with the `encoding` parameter to specify the encoding of the CSV file.\n",
      "```\n",
      "df.to_csv('output.csv', encoding='utf-8')\n",
      "```\n",
      "You can also use the `to_csv()` method with the `na_rep` parameter to specify the value to use for missing values in the CSV file.\n",
      "```\n",
      "df.to_csv('output.csv', na_rep='NA')\n",
      "```\n",
      "You can also use the `to_csv()` method with the `header` parameter to specify whether the sheet index should be included as the first row of the CSV file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm_chain.run(\"write me a python code that convert excel to csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create our Tool\n",
    "- 1st Tool : To create summarizer tools\n",
    "- 2nd Tool : To create Q&A tools\n",
    "- 3rd Tool : To create LLM Math Chain tools\n",
    "- 4th Tool : To create a general tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### summarize\n",
    "summarize_chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "summarize_general = Tool(\n",
    "    name='summarization Tool',\n",
    "    func=summarize_chain.run,\n",
    "    description='use this tool when summarizing information'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## QA closed book\n",
    "\n",
    "custom_prompt_template = \"\"\"[INST] <<SYS>>\n",
    "Your name is Kelly, You are helpful assistant, you always open and only answer for the assistant then you stop.\n",
    "If you don't know the answer, just say you don't know and submit the request to hotline@xfab.com for further assistance.\n",
    "<</SYS>>\n",
    "\n",
    "Question: {question}\n",
    "[/INST]\"\"\"\n",
    "\n",
    "#prompt = PromptTemplate(template=\"Question: {question}\\nAnswer:\", input_variables=[\"question\"])\n",
    "\n",
    "prompt = PromptTemplate(input_variables=['question'],template=custom_prompt_template)\n",
    "qachain = LLMChain(llm=llm, prompt=prompt)\n",
    "QA_general = Tool(\n",
    "    name='Question Answer',\n",
    "    func=qachain.run,\n",
    "    description='use this tool when answering questions'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlukas/Desktop/My_Project/AI_CTS/aicts/lib/python3.10/site-packages/langchain/chains/llm_math/base.py:51: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### Math \n",
    "llm_math = LLMMathChain(llm=llm, verbose=True)\n",
    "llm_math_tool = Tool(\n",
    "    name='Calculator',\n",
    "    func=llm_math.run,\n",
    "    description='use this tool to perform calculations'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### General Tools\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "genneral_tool = Tool(\n",
    "    name='Language Model',\n",
    "    func=llm_chain.run,\n",
    "    description='use this tool for general purpose queries and logic'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we combine the Tool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.extend([summarize_general, QA_general, llm_math_tool, genneral_tool])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here we'll initialize the agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Zero Shot\n",
    "agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    #verbose=True,\n",
    "    max_iterations=3,\n",
    "    handle_parsing_errors=\"Check your output and make sure it conforms!\",\n",
    "    early_stopping_method=\"generate\", #to perform one FINAL pass through the LLM to generate an output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using conversational react with memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "agent = initialize_agent(\n",
    "    agent=\"conversational-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=4,\n",
    "    memory=memory,\n",
    "    handle_parsing_errors=\"Check your output and make sure it conforms!\",\n",
    "    early_stopping_method=\"generate\", #to perform one FINAL pass through the LLM to generate an output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent(\"Write me python code that convert excel to csv ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response= agent.run(\"Write me a python code that convert excel to csv?\")\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "        response = str(e)\n",
    "        if response.startswith(\"Could not parse LLM output: `\"):\n",
    "            response = response.removeprefix(\"Could not parse LLM output: `\").removesuffix(\"`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response= agent.run(\"Please Write me an arduino code that read the ultrasonic sensor distance and turn the buzzer if distance less than 5cm\")\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "        response = str(e)\n",
    "        if response.startswith(\"Could not parse LLM output: `\"):\n",
    "            response = response.removeprefix(\"Could not parse LLM output: `\").removesuffix(\"`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response= agent.run(\"Help me to find x to equation , find x for 4x+2 = 5x\")\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "        response = str(e)\n",
    "        if response.startswith(\"Could not parse LLM output: `\"):\n",
    "            response = response.removeprefix(\"Could not parse LLM output: `\").removesuffix(\"`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response= agent.run(\"Show me the calculation step\")\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "        response = str(e)\n",
    "        if response.startswith(\"Could not parse LLM output: `\"):\n",
    "            response = response.removeprefix(\"Could not parse LLM output: `\").removesuffix(\"`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
