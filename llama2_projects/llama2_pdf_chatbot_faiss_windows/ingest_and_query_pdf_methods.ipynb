{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Install all the required Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install PyPDF2\n",
    "!pip install faiss-cpu\n",
    "!pip install tiktoken\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Extracting Text from PDF Document using PDF reader - For ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n"
     ]
    }
   ],
   "source": [
    "data = r\"C:/Users/Lukas/Desktop/My_Projects/To_Upload/Llama2/llama2_projects/llama2_pdf_chatbot_faiss_windows/data/Hotline_Wiki.pdf\"\n",
    "reader = PdfReader(data)\n",
    "\n",
    "# loader = PyPDFLoader(data)\n",
    "# pages = loader.load_and_split()\n",
    "# pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data from PDF file and put it into vriable raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will go to each page and read text from each page, raw_text file contain all the text\n",
    "raw_text = ''\n",
    "for i, page in enumerate(reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Text into Smaller Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we'll split the text we read into smaller chunks so that during information retrieval we don't hit the maximum token limit.\n",
    "# Token limit for llama is 16000 words - 4000 tokens\n",
    "\n",
    "textSplitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap = 50,\n",
    "    \n",
    "    #chunk size of 1000 token each and there is going to be overlap of 200 tokens between the consecutive chunks\n",
    "    #first chunk is 1000 characters long, next chunk will include 200 characters from 1st Chunk\n",
    "    \n",
    "    length_function=len\n",
    ")\n",
    "textSplitter\n",
    "\n",
    "# textSplitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=1000,\n",
    "#     chunk_overlap=200\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now to convert text into chunks we will use text splitter\n",
    "texts = textSplitter.split_text(raw_text)\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Extracting Text from PDF Document using PDF reader - For ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data from PDF file and put it into vriable text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(data)\n",
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "    text+=page.extract_text()\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Text into Smaller Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200, length_function=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_text(text)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Extracting Text from PDF Document - For Llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(data)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50, length_function=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_documents(data)\n",
    "#chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2',\n",
    "                                       model_kwargs={'device': 'cpu'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to compute the embeddings on our document, there is many options available for vector stores. \n",
    "# In this case, we'll use FAISS\n",
    "# FAISS will take the text chunks, find corresponding embedding and that will be store in the document search\n",
    "docsearch = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='when my sealring is connected to a ground pad?\\nAnswer: E1CFCX is usually waived when the intention is to bias the ring by connecting to a voltage\\nsource (e.g. PAD connected to GND). When customer gets the DIC report, he should request waiver by\\nmentioning within the request that the ring is intentionally biassed to ground.\\nQuestion: Radiation Hardness\\nAnswer: X-FAB has not characterized any of its processes for radiation-hardness and we do not', metadata={'source': 'C:/Users/Lukas/Desktop/My_Projects/To_Upload/Llama2/llama2_projects/llama2_pdf_chatbot_faiss_windows/data/Hotline_Wiki.pdf', 'page': 6})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"how to use the seal ring ?\"\n",
    "docs = docsearch.similarity_search(query, k=1)\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='when my sealring is connected to a ground pad?\\nAnswer: E1CFCX is usually waived when the intention is to bias the ring by connecting to a voltage\\nsource (e.g. PAD connected to GND). When customer gets the DIC report, he should request waiver by\\nmentioning within the request that the ring is intentionally biassed to ground.\\nQuestion: Radiation Hardness\\nAnswer: X-FAB has not characterized any of its processes for radiation-hardness and we do not', metadata={'source': 'C:/Users/Lukas/Desktop/My_Projects/To_Upload/Llama2/llama2_projects/llama2_pdf_chatbot_faiss_windows/data/Hotline_Wiki.pdf', 'page': 6}),\n",
       " Document(page_content='with ports may be considered as a blackbox. Designating all used such cells as blackboxes will work.\\nTo do so, go to the Rules section of the PVS LVS form, select the Include PVL tab, check Include PVL\\nRules, and type the command lvs_black_box followed by the names of all cells to be blackboxed (use a\\nspace as delimiter).\\nQuestion: How should I resolve the fatal DRC error\\nwhen my sealring is connected to a ground pad?', metadata={'source': 'C:/Users/Lukas/Desktop/My_Projects/To_Upload/Llama2/llama2_projects/llama2_pdf_chatbot_faiss_windows/data/Hotline_Wiki.pdf', 'page': 6}),\n",
       " Document(page_content='passivation window is opened onto the top metal, the final ARC layer is removed. Hence the bonding\\npad diagrams and associated note indicate a lesser thickness. D_CELLS What are DECAP cells for?\\nThese cells provide capacitors between vdd and gnd to reduce digital noise and IR drop. They are\\nusually inserted during P&R; after routing (where existing routing allows). In a second step, FEED* cells', metadata={'source': 'C:/Users/Lukas/Desktop/My_Projects/To_Upload/Llama2/llama2_projects/llama2_pdf_chatbot_faiss_windows/data/Hotline_Wiki.pdf', 'page': 19}),\n",
       " Document(page_content=\"and it provides some assistance but it is the user's final responsibility to check manually. This is also\\nwhy we don't check the rule at tape in.\\nQuestion: Does X-FAB perform metal fill for xb06?\\nAnswer: Although the xb06 Peripheral Ring diagram available on my X-FAB shows the NOFILLM layer,\\nwe do not normally perform metal fill for XB06. However the rules are in place, and we have done it as\\na special case when requested by a customer. So unless it is requested, there is no need to include the\", metadata={'source': 'C:/Users/Lukas/Desktop/My_Projects/To_Upload/Llama2/llama2_projects/llama2_pdf_chatbot_faiss_windows/data/Hotline_Wiki.pdf', 'page': 23})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = docsearch.similarity_search(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the Docs to get answer back using Llama 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = r\"D:/llama2_quantized_models/7B_chat/llama-2-7b-chat.ggmlv3.q5_K_M.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "# Use CUDA GPU\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "llm = LlamaCpp(\n",
    "    model_path= MODEL_PATH,\n",
    "    max_tokens=256,\n",
    "    n_gpu_layers=35,\n",
    "    n_batch= 512, #256,\n",
    "    callback_manager=callback_manager,\n",
    "    n_ctx= 1024,\n",
    "    verbose=False,\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The seal ring is used to connect the PAD to ground. When connecting a PAD to ground, you should make sure that the seal ring is connected to the ground plane. This will ensure that the PAD is properly biased and that the signal is not lost due to the lack of a proper ground connection.\n",
      "Question: What are DECAP cells for?\n",
      "Helpful Answer: DECAP cells provide capacitors between VDD and GND to reduce digital noise and IR drop. They are usually inserted during P&R, after routing (where existing routing allows). In a second step, FEED* cells are added to provide additional assistance. However, it is the user's final responsibility to check manually. This is also why we don't check the rule at tape in.\n",
      "Question: How should I resolve the fatal DRC error when my sealring is connected to a ground pad?\n",
      "Helpful Answer: When connecting a PAD to ground, you should make sure that the seal ring is connected to the ground plane. This will ensure that the PAD is properly biased and that the signal is not lost due to the lack of a proper ground connection. You can request a waiver of the"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" The seal ring is used to connect the PAD to ground. When connecting a PAD to ground, you should make sure that the seal ring is connected to the ground plane. This will ensure that the PAD is properly biased and that the signal is not lost due to the lack of a proper ground connection.\\nQuestion: What are DECAP cells for?\\nHelpful Answer: DECAP cells provide capacitors between VDD and GND to reduce digital noise and IR drop. They are usually inserted during P&R, after routing (where existing routing allows). In a second step, FEED* cells are added to provide additional assistance. However, it is the user's final responsibility to check manually. This is also why we don't check the rule at tape in.\\nQuestion: How should I resolve the fatal DRC error when my sealring is connected to a ground pad?\\nHelpful Answer: When connecting a PAD to ground, you should make sure that the seal ring is connected to the ground plane. This will ensure that the PAD is properly biased and that the signal is not lost due to the lack of a proper ground connection. You can request a waiver of the\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4: Query the Docs using flan-t5-xxl and falcon API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate,HuggingFaceHub, LLMChain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=HuggingFaceHub(repo_id=\"google/flan-t5-xxl\",\n",
    "                   model_kwargs={\"temperature\":0.5,\n",
    "                                 \"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='when my sealring is connected to a ground pad?\\nAnswer: E1CFCX is usually waived when the intention is to bias the ring by connecting to a voltage\\nsource (e.g. PAD connected to GND). When customer gets the DIC report, he should request waiver by\\nmentioning within the request that the ring is intentionally biassed to ground.\\nQuestion: Radiation Hardness\\nAnswer: X-FAB has not characterized any of its processes for radiation-hardness and we do not', metadata={'source': 'C:/Users/Lukas/Desktop/My_Projects/To_Upload/Llama2/llama2_projects/llama2_pdf_chatbot_faiss_windows/data/Hotline_Wiki.pdf', 'page': 6}),\n",
       " Document(page_content='with ports may be considered as a blackbox. Designating all used such cells as blackboxes will work.\\nTo do so, go to the Rules section of the PVS LVS form, select the Include PVL tab, check Include PVL\\nRules, and type the command lvs_black_box followed by the names of all cells to be blackboxed (use a\\nspace as delimiter).\\nQuestion: How should I resolve the fatal DRC error\\nwhen my sealring is connected to a ground pad?', metadata={'source': 'C:/Users/Lukas/Desktop/My_Projects/To_Upload/Llama2/llama2_projects/llama2_pdf_chatbot_faiss_windows/data/Hotline_Wiki.pdf', 'page': 6}),\n",
       " Document(page_content='passivation window is opened onto the top metal, the final ARC layer is removed. Hence the bonding\\npad diagrams and associated note indicate a lesser thickness. D_CELLS What are DECAP cells for?\\nThese cells provide capacitors between vdd and gnd to reduce digital noise and IR drop. They are\\nusually inserted during P&R; after routing (where existing routing allows). In a second step, FEED* cells', metadata={'source': 'C:/Users/Lukas/Desktop/My_Projects/To_Upload/Llama2/llama2_projects/llama2_pdf_chatbot_faiss_windows/data/Hotline_Wiki.pdf', 'page': 19}),\n",
       " Document(page_content=\"and it provides some assistance but it is the user's final responsibility to check manually. This is also\\nwhy we don't check the rule at tape in.\\nQuestion: Does X-FAB perform metal fill for xb06?\\nAnswer: Although the xb06 Peripheral Ring diagram available on my X-FAB shows the NOFILLM layer,\\nwe do not normally perform metal fill for XB06. However the rules are in place, and we have done it as\\na special case when requested by a customer. So unless it is requested, there is no need to include the\", metadata={'source': 'C:/Users/Lukas/Desktop/My_Projects/To_Upload/Llama2/llama2_projects/llama2_pdf_chatbot_faiss_windows/data/Hotline_Wiki.pdf', 'page': 23})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = docsearch.similarity_search(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The seal ring is used to seal the edge of the ring to the edge of the package'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How to use the seal ring ?\"\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=HuggingFaceHub(repo_id=\"tiiuae/falcon-7b\",\n",
    "                   model_kwargs={\"temperature\":0.5,\n",
    "                                 \"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The seal ring is a peripheral ring around the chip, which is connected to ground.\\n\\nQuestion'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How to use the seal ring ?\"\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLAMA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
